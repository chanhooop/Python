{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f111d5",
   "metadata": {},
   "source": [
    "# 데이터 다운로드 하기\n",
    ":인터넷에서 지정된 파일을 내 pc에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9bbf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import urllib.request\n",
    "\n",
    "# URL과 저장경로 지정하기\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"./Data/test.png\"\n",
    "\n",
    "# 다운로드 하기\n",
    "urllib.request.urlretrieve(url, savename)\n",
    "print(\"저장 되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5d56f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import urllib.request\n",
    "\n",
    "# URL과 저장경로 지정하기\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\" b\n",
    "savename = \"./Data/test1.png\"\n",
    "\n",
    "# 다운로드 하기\n",
    "mem = urllib.request.urlopen(url).read()\n",
    "\n",
    "# 파일로 저장하기\n",
    "with open(savename, \"wb\") as f:\n",
    "    f.write(mem)\n",
    "print(\"저장 되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ea39f",
   "metadata": {},
   "source": [
    "# BeatifulSoup로 Scraping하기\n",
    ": 간단하게 HTML과 XML에서 정보를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e6772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\chanholee\\anaconda3\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chanholee\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5592a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Header</h1>\n",
      "<p> Line 1을 서술 </p>\n",
      "------------\n",
      "h1= Header\n",
      "h1= Header\n",
      "p1  Line 1을 서술 \n",
      "p1  Line 1을 서술 \n"
     ]
    }
   ],
   "source": [
    "# 기본 사용법\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML Sample \n",
    "\n",
    "html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <h1>Header</h1>\n",
    "                <p> Line 1을 서술 </p>\n",
    "            </body>\n",
    "        </html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "#print(soup)\n",
    "\n",
    "# 원하는 부분 추출하기 (태그를 통한 스크래핑)\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "print(h1)\n",
    "print(p1)\n",
    "print(\"------------\")\n",
    "# Text만 출력\n",
    "print(\"h1=\", h1.string)\n",
    "print(\"h1=\", h1.text)\n",
    "print(\"p1\", p1.string)\n",
    "print(\"p1\", p1.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c3dae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\"> Header </h1>\n",
      "<p1 id=\"body\"> Line 1을 서술 \n",
      "</p1>\n",
      "title=  Header \n",
      "body=  Line 1을 서술 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# id로 요소를 추출하기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML Sample\n",
    "\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <h1 id=\"title\"> Header </h1>\n",
    "            <p1 id=\"body\"> Line 1을 서술 </p>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 원하는 부분 추출하기\n",
    "title = soup.find(id='title')\n",
    "body = soup.find(id=\"body\")\n",
    "print(title)\n",
    "print(body)\n",
    "\n",
    "# Text만 출력\n",
    "print(\"title=\", title.text)\n",
    "print(\"body=\", body.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a14797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver >>> http://www.naver.com\n",
      "daum >>> http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 요소 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML Sample\n",
    "\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <ul>\n",
    "                <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "                <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "            </ul>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 원하는 부분 추출하기\n",
    "# soup.find('a')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "# 링크 목록 출력\n",
    "for link in links:\n",
    "#   print(link.string)\n",
    "#    print(link.attrs['href']) #attrs = attribute 태그\n",
    "    \n",
    "    href = link.attrs['href']\n",
    "    text = link.string\n",
    "    print(text, \">>>\", href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8641629d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-d2ead2f6855c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# 데이터 정리하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mlist_wfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mexcept_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\">\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# 기상청 자료 활용하기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=109\"\n",
    "\n",
    "# data 가져오기\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# print(soup)\n",
    "\n",
    "\n",
    "# 원하는 데이터 추출하기\n",
    "title = soup.find('title').string\n",
    "print(title)\n",
    "#wf = str(soup.find('wf').string)\n",
    "wf = soup.find('wf').string\n",
    "\n",
    "# 데이터 정리하기\n",
    "list_wfs = list(wf)\n",
    "print(list_wfs)\n",
    "except_char = ['<','b','r','/',\">\"]\n",
    "result = \"\"\n",
    "\n",
    "for lwf in list_wfs:\n",
    "    if lwf not in except_char:\n",
    "        result += lwf\n",
    "print('-'*100)\n",
    "print(result)\n",
    "\n",
    "\n",
    "#wlist = wf.split('<br />')\n",
    "\n",
    "#print(wlist)\n",
    "#for w in wlist:\n",
    "#    print(w)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7146e3a",
   "metadata": {},
   "source": [
    "# css 선택자 사용하기\n",
    "soup.select_one() : css선택자로 요소 하나를 추출.\n",
    "soup.select() : css선택자로 요소 여러개를 리스트로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc307643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <div id = \"meigen\">\n",
    "                <h1>위키 북스<h1>\n",
    "                <ul class=\"items\">\n",
    "                    <li>유니티 게임 이펙트 입문서</li>\n",
    "                    <li>모던 웹사이트 디자인의 정석</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 필요한 부분 css로 추출하기\n",
    "# 타이틀 부분 추출하기\n",
    "\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string  # id:# , class:.  , > : 자손.  \" \" : 후손\n",
    "print(h1)\n",
    "\n",
    "# 목록 부분 추출하기\n",
    "li_lists = soup.select(\"div#meigen > ul.items > li\")\n",
    "print(li_lists)\n",
    "for li in li_lists:\n",
    "    print(li.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b18d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 금융에서 환율 정보 추출하기\n",
    "# https://finance.naver.com/marketindex/\n",
    "# #exchangeList > li.on > a.head.usd > div > span.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8b6a68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd / krw :  1,143.50\n"
     ]
    }
   ],
   "source": [
    "# 미국 환율 가져오기\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# HTML\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)\n",
    "\n",
    "#데이터 추출하기\n",
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd / krw : \", price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "53012366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 :  1,144.00\n",
      "일본 :  1,036.42\n",
      "유럽연합 :  1,358.16\n",
      "중국 :  176.85\n"
     ]
    }
   ],
   "source": [
    "# id:# , class:.  , > : 자손.  \" \" : 후손\n",
    "\n",
    "# 미국, 일본, 유렵연합, 중국의 환율\n",
    "# HTML\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)\n",
    "\n",
    "#데이터 추출하기\n",
    "prices = soup.select(\"div.head_info > span.value\")\n",
    "\n",
    "#for price in prices:\n",
    "#   print(price.string)\n",
    "print(\"미국 : \", prices[0].string)\n",
    "print(\"일본 : \", prices[1].string)\n",
    "print(\"유럽연합 : \", prices[2].string)\n",
    "print(\"중국 : \", prices[3].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "72e720fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘과 바람과 별과 시\n",
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n",
      "흰 그림자\n",
      "사랑스런 추억\n",
      "흐르는 거리\n",
      "쉽게 씌어진 시\n",
      "봄\n",
      "참회록\n",
      "간(肝)\n",
      "위로\n",
      "팔복\n",
      "못자는밤\n",
      "달같이\n",
      "고추밭\n",
      "아우의 인상화\n",
      "사랑의 전당\n",
      "이적\n",
      "비오는 밤\n",
      "산골물\n",
      "유언\n",
      "창\n",
      "바다\n",
      "비로봉\n",
      "산협의 오후\n",
      "명상\n",
      "소낙비\n",
      "한난계\n",
      "풍경\n",
      "달밤\n",
      "장\n",
      "밤\n",
      "황혼이 바다가 되어\n",
      "아침\n",
      "빨래\n",
      "꿈은 깨어지고\n",
      "산림\n",
      "이런날\n",
      "산상\n",
      "양지쪽\n",
      "닭\n",
      "가슴 1\n",
      "가슴 2\n",
      "비둘기\n",
      "황혼\n",
      "남쪽 하늘\n",
      "창공\n",
      "거리에서\n",
      "삶과 죽음\n",
      "초한대\n",
      "산울림\n",
      "해바라기 얼굴\n",
      "귀뚜라미와 나와\n",
      "애기의 새벽\n",
      "햇빛·바람\n",
      "반디불\n",
      "둘 다\n",
      "거짓부리\n",
      "눈\n",
      "참새\n",
      "버선본\n",
      "편지\n",
      "봄\n",
      "무얼 먹구 사나\n",
      "굴뚝\n",
      "햇비\n",
      "빗자루\n",
      "기왓장 내외\n",
      "오줌싸개 지도\n",
      "병아리\n",
      "조개껍질\n",
      "겨울\n",
      "트루게네프의 언덕\n",
      "달을 쏘다\n",
      "별똥 떨어진 데\n",
      "화원에 꽃이 핀다\n",
      "종시\n"
     ]
    }
   ],
   "source": [
    "# 윤동주 시안 작품 가져오기\n",
    "# #mw-content-text > div.mw-parser-output > ul:nth-child(6) > li > b > a\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# HTML\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)\n",
    "\n",
    "#데이터 추출하기\n",
    "a_list= soup.select('#mw-content-text > div.mw-parser-output > ul > li a')\n",
    "#print(a_list)\n",
    "\n",
    "for a in a_list:\n",
    "    if a.string == \"증보판\":\n",
    "        continue             # 무시하고 진행응 continue\n",
    "    print(a.string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d82c2",
   "metadata": {},
   "source": [
    "## 다음 영화 연간 순위 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "35dfc1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 남산의 부장들\n",
      "2 : 다만 악에서 구하소서\n",
      "3 : 반도\n",
      "4 : 히트맨\n",
      "5 : 테넷\n",
      "6 : 백두산\n",
      "7 : #살아있다\n",
      "8 : 강철비2: 정상회담\n",
      "9 : 담보\n",
      "10 : 닥터 두리틀\n",
      "11 : 삼진그룹 영어토익반\n",
      "12 : 정직한 후보\n",
      "13 : 도굴\n",
      "14 : 클로젯\n",
      "15 : 오케이 마담\n",
      "16 : 해치지않아\n",
      "17 : 천문: 하늘에 묻는다\n",
      "18 : 결백\n",
      "19 : 1917\n",
      "20 : 작은 아씨들\n",
      "21 : 미드웨이\n",
      "22 : 시동\n",
      "23 : 지푸라기라도 잡고 싶은 짐승들\n",
      "24 : 미스터 주: 사라진 VIP\n",
      "25 : 인비저블맨\n",
      "26 : 나쁜 녀석들: 포에버\n",
      "27 : 국제수사\n",
      "28 : 침입자\n",
      "29 : 스타워즈: 라이즈 오브 스카이워커\n",
      "30 : 스파이 지니어스 \n",
      "31 : 이웃사촌\n",
      "32 : 온워드: 단 하루의 기적\n",
      "33 : 소리도 없이\n",
      "34 : 버즈 오브 프레이(할리 퀸의 황홀한 해방)\n",
      "35 : 원더 우먼 1984\n",
      "36 : 겨울왕국 2\n",
      "37 : 오! 문희\n",
      "38 : 그린랜드\n",
      "39 : 위대한 쇼맨\n",
      "40 : 런\n",
      "41 : 뮬란\n",
      "42 : 내가 죽던 날\n",
      "43 : 기생충\n",
      "44 : 신비아파트 극장판 하늘도깨비 대 요르문간드\n",
      "45 : 프리즌 이스케이프\n",
      "46 : 검객\n",
      "47 : 조제\n",
      "48 : 사라진 시간\n",
      "49 : 밤쉘: 세상을 바꾼 폭탄선언\n",
      "50 : 알라딘\n"
     ]
    }
   ],
   "source": [
    "#https://movie.daum.net/boxoffice/yearly?year=2021\n",
    "# #mainContent > div > div.box_boxoffice > ol > li:nth-child(1) > div > div.thumb_cont > strong > a\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "\n",
    "# HTML\n",
    "url = \"https://movie.daum.net/boxoffice/yearly?year=2021\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)\n",
    "#b_list = soup.select('#mainContent > div > div.box_boxoffice > ol > li > div > div.thumb_cont > strong > a')\n",
    "b_list = soup.select('strong a')\n",
    "n = 1\n",
    "for b in b_list:\n",
    "    print(n, \":\", b.string)\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68dac0",
   "metadata": {},
   "source": [
    "# 다음 IT News 많이 본 뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "305bd8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://v.daum.net/v/20210713140143407 : 이재명, 긴급 기자회견..\"4차 팬데믹 못막으면 전면봉쇄 불가피\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713132549158 : BJ철구, 7살딸과 '여캠BJ 새엄마 월드컵'..아동학대 논란\n",
      "                                    \n",
      "https://v.daum.net/v/20210713144711324 : \"일출 보려다 물어뜯길 뻔\"..성산일출봉까지 점령한 야생들개\n",
      "                                    \n",
      "https://v.daum.net/v/20210713124446148 : \"누나가 무슨 부모야\" 친누나 30차례 찔러 살해한 남동생.. 무기징역 구형\n",
      "                                    \n",
      "https://v.daum.net/v/20210713114057051 : \"술집 못가니 호텔 가자\" 60대 유명화가, 20대 성폭행 의혹\n",
      "                                    \n",
      "https://v.daum.net/v/20210713133842565 : 정은경 '靑 방역기획관에 밀렸나' 질문에 \"소신껏 하고 있다\" 일축\n",
      "                                    \n",
      "https://v.daum.net/v/20210713144622300 : \"확진자인데 와서 미안\" 농담에 카페 영업중단..업무방해 무죄\n",
      "                                    \n",
      "https://v.daum.net/v/20210713113441712 : 우리은행 본점서 코로나19 집단감염..\"발설 시 엄벌\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713113230612 : 홍남기, 전국민 지원금 합의에 \"동의 안한다\"..여당과 충돌\n",
      "                                    \n",
      "https://v.daum.net/v/20210713143600846 : 청와대 앞에 착륙한 미끼 전투기, 힘을 보여주고 싶었다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713133106300 : '천조국 최종병기' 대륙간탄도미사일 미니트맨 Ⅲ\n",
      "                                    \n",
      "https://v.daum.net/v/20210713120602280 : 습도 높으면 35도서도 치명타..습한 한국 여름 무서운 이유\n",
      "                                    \n",
      "https://v.daum.net/v/20210713144944406 : 중등교원 양성 규모 축소..사범대 나와야 국영수 교사된다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713115624812 : 무려 60년간 조용하던 쿠바인들은 왜 들고 일어났나\n",
      "                                    \n",
      "https://v.daum.net/v/20210713135902248 : \"이 시국에 떼창?\" 팬들 반발에..백기 든 '미스터트롯' 공연\n",
      "                                    \n",
      "https://v.daum.net/v/20210713131902974 : \"돼지코 같다\" 싸늘한 반응..BMW 4시리즈 참혹한 결과\n",
      "                                    \n",
      "https://v.daum.net/v/20210713115724852 : \"한국인 DNA에 표현력 없다\" 바이올린 거장 주커만 인종차별\n",
      "                                    \n",
      "https://v.daum.net/v/20210713111827741 : \"살려주세요\" 외침에 바로 '풍덩'..초등생 3명 잇따라 구한 40대\n",
      "                                    \n",
      "https://v.daum.net/v/20210713133325380 : 예고 없이 잡힌 미스터트롯 전주 콘서트, 잇단 항의에 취소\n",
      "                                    \n",
      "https://v.daum.net/v/20210713150601168 : \"철학 붕괴\" 윤희숙 연일 이준석 비판..하태경 \"자해정치\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713125407426 : 짧고 굵은 장마 19일까지..20일부터 강한 폭염 온다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713142508329 : 부산도 위태롭다..유흥시설 넘어 식당·학교 등 전방위 확산\n",
      "                                    \n",
      "https://v.daum.net/v/20210713131915980 : \"4000모 이식한거 맞아?\"..모발 이식 사진은 의료기록인가, 아닌가\n",
      "                                    \n",
      "https://v.daum.net/v/20210713140846683 : 중·고교 교사 양성 규모 축소한다..사범대 안나오면 국영수 교사 되기 어려워\n",
      "                                    \n",
      "https://v.daum.net/v/20210713105323294 : 친누나 살해·시신유기 뒤 누나 행세 20대..부모, 눈물로 선처 호소\n",
      "                                    \n",
      "https://v.daum.net/v/20210713115700827 : \"내년 하반기 미 금융시장 대폭락 온다\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713132558167 : 정은경, 55~59세 예약 중단에 \"안내 못드려 송구..충분히 접종 가능\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713105938609 : 日, 또다시 독도 영유권 도발..文 대통령 '방일' 영향 미칠까\n",
      "                                    \n",
      "https://v.daum.net/v/20210713140105375 : 연인 관계 2/3, 친구서 발전 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713122837887 : 이준석 \"宋과의 고민, 대변인들 거치며 전달안된듯\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713141559923?s=eRIGHT_MANY_TOT=R : 옥주현 \"큰아버지 빚 상속받았다..정말 황당\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713140557574?s=eRIGHT_MANY_TOT=R : 'SKY캐슬' 이유진, 벌써 18살..184cm 넘는 모델 피지컬\n",
      "                                    \n",
      "https://v.daum.net/v/20210713114046042?s=eRIGHT_MANY_TOT=R : '임신 중 별세' 서보라미 출연 '노는 언니', 오늘 결방 \"잠정 연기\" \n",
      "                                    \n",
      "https://v.daum.net/v/20210713133012274?s=eRIGHT_MANY_TOT=R : 이성경 \"미치광이 수준으로 골프에 빠져있다\" 고백 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713135922267?s=eRIGHT_MANY_TOT=R : '장윤정♥︎' 도경완 \"우리 하영이 언니 되겠네\" 셋째 '캠핑 베이비' 욕심\n",
      "                                    \n",
      "https://v.daum.net/v/20210713133018277?s=eRIGHT_MANY_TOT=R : 정은지 \"연예인 친구 많은 줄 아는데 하나도 없어, 난 자발적 아웃사이더\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713142325250?s=eRIGHT_MANY_TOT=R : 김동현, 격투기 성공 전 연봉 공개 \"서울 호텔 하수구 다 뚫어\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713112104884?s=eRIGHT_MANY_TOT=R : 김준호 \"이혼한지 얼마 안 돼 위축돼 있었는데 '돌싱포맨' 후 달라졌다\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713101435560?s=eRIGHT_MANY_TOT=R : 도경완 \"하영이 언니 되겠네\" ♥장윤정과 캠핑 베이비 욕심 불끈\n",
      "                                    \n",
      "https://v.daum.net/v/20210713110846230?s=eRIGHT_MANY_TOT=R : '양다리 논란' 하준수♥안가연 '코빅' 하차요구까지..오늘 녹화 강행?\n",
      "                                    \n",
      "https://v.daum.net/v/20210712215002263?s=eRIGHT_MANY_TOT=R : 박민우, 오토바이 사고로 중환자실..父 \"3년째 간병, 살려만 달라 기도\" \n",
      "                                    \n",
      "https://v.daum.net/v/20210713101415551?s=eRIGHT_MANY_TOT=R : 팀♥김보라, 러브하우스 최초 공개..우울증·공황장애 고백 폭풍 오열\n",
      "                                    \n",
      "https://v.daum.net/v/20210713145206505?s=eRIGHT_MANY_TOT=R : '미스터트롯' 콘서트 강행, 팬들까지 등 돌리게 한 악수 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713100958340?s=eRIGHT_MANY_TOT=R : 서인영, 코로나19 확진판정..방송 스케줄 전면 취소\n",
      "                                    \n",
      "https://v.daum.net/v/20210713132701186?s=eRIGHT_MANY_TOT=R : 매드몬스터 탄 \"얼굴 공개 못하는 이유, 피부팀이 조명 덜 받으면 좋겠다고\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713132134022?s=eRIGHT_MANY_TOT=R : 논란의 흑인 '인어공주', 촬영 종료..할리 베일리 인증샷\n",
      "                                    \n",
      "https://v.daum.net/v/20210713141200783?s=eRIGHT_MANY_TOT=R : 윤스테이 닮은 '우도주막'.. 이들이 나오자 달라졌다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713133936590?s=eRIGHT_MANY_TOT=R : '-8kg' 홍현희, 다이어트하더니 위 줄었나..천뚱과 밥그릇 크기 차이 보니\n",
      "                                    \n",
      "https://v.daum.net/v/20210713115407744?s=eRIGHT_MANY_TOT=R : 임원희 \"사랑의 교통사고 당하고 싶어..'돌싱포맨'서 하차해도 괜찮아\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713152920046?s=eRIGHT_MANY_TOT=R : '오토바이 사고' 박민우, 2년전 킹콩by스타쉽 계약만료→재활 근황 관심 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713053228886?s=eRIGHT_MANY_TOT=R : 이동국, 한껏 꾸민 딸 재아 보며 흐뭇 \"아리아나 그란데 같아\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713145002412?s=eRIGHT_MANY_TOT=R : \"성격 차이?\"..탁재훈, 이상민에 이혼 언급 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713114631358?s=eRIGHT_MANY_TOT=R : 박명수 \"나영석 PD, 갑작스러운 연락도 반겨줘 고마워\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713092817304?s=eRIGHT_MANY_TOT=R : 옥주현 \"큰아버지 빚 상속받아..황당했다\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713095512584?s=eRIGHT_MANY_TOT=R : '대탈출4' 무성의한 출연진 태도, 시청자 혹평 쏟아져 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713144357202?s=eRIGHT_MANY_TOT=R : 옥주현 \"돌아가신 큰아버지 빚 상속받았다, 정말 황당\" \n",
      "                                    \n",
      "https://v.daum.net/v/20210713063205575?s=eRIGHT_MANY_TOT=R : '양다리 연애' 맞지만, 억울해!..권민아 '추가 폭로' 예고→하준수 '법적 대응' 시사 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713134401703?s=eRIGHT_MANY_TOT=R : 장도연 \"300만원, 내 운명을 바꿨죠\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713120822360?s=eRIGHT_MANY_TOT=R : \"술 먹은 줄\".. 탁재훈·이상민→임원희 '돌싱포맨' 선 넘는 조합, 다시 뭉쳤다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713121124461?s=eRIGHT_MANY_TOT=R : 김소영 \"출산 후 소변줄 꽂고..시어머니 손주+아들 걱정만\" \n",
      "                                    \n",
      "https://v.daum.net/v/20210713114515281 : 케인, 결국 폭발..\"당신들은 팬도 아니야\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713141552918 : 승부조작 대가 받은 윤성환, \"혐의 사실 모두 인정\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713112703265 : \"내가 PK 차고 싶다고 했잖아!\" 잉글랜드 승부차기 논란 일파만파\n",
      "                                    \n",
      "https://v.daum.net/v/20210713105817524 : 한국 올림픽 금메달 예측 7위..스페인 1위 일본 6위\n",
      "                                    \n",
      "https://v.daum.net/v/20210713130323627 : \"왜 우리는 야구 하는거죠?\" 그날 최형우가 던진 돌발 질문 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713105003169 : '무단침입·칼 부림·성폭행 주장'까지..충격과 공포의 웸블리\n",
      "                                    \n",
      "https://v.daum.net/v/20210713110449047 : 대구마저 코로나 확진자 발생..선수 1명 확진\n",
      "                                    \n",
      "https://v.daum.net/v/20210713112607210 : 해리 케인 \"너 같은 팬 필요없어\"..인종차별 사태 비난\n",
      "                                    \n",
      "https://v.daum.net/v/20210713120048055 : 알론소, 역대 3번째 홈런더비 2연패 달성..연봉보다 상금이 많아\n",
      "                                    \n",
      "https://v.daum.net/v/20210713113002424 : 황의조의 보르도, 2부 강등→리그앙으로 구사일생..'결정 뒤집혔다'\n",
      "                                    \n",
      "https://v.daum.net/v/20210713132226038 : 연봉 '1880억' 계약 종료..메시 하루에 '1억' 손실 중\n",
      "                                    \n",
      "https://v.daum.net/v/20210713140037351 : 확진자 속출에 '뜬금없는' 자가검사 키트 홍보한 KBO, 방역 전문가들 \"PCR 검사가 더 효율적인데 왜?\" \n",
      "                                    \n",
      "https://v.daum.net/v/20210713143457811 : 테니스·골프 스타들 줄줄이 불참.. '별' 볼일 없어진 도쿄올림픽\n",
      "                                    \n",
      "https://v.daum.net/v/20210713123900058 : NC와 두산은 흉흉한 소문에 대한 진실부터 밝혀라\n",
      "                                    \n",
      "https://v.daum.net/v/20210713093902801 : 뒤끝작렬..맥그리거 \"수술 성공적..부정한 승리 축하한다\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713151723608 : 메시한테 이런 면모가..우승 세리머니하다 동료 호통친 사연 공개\n",
      "                                    \n",
      "https://v.daum.net/v/20210713084254640 : 대한민국 선수들 절대 잉글랜드 축구 선수들 닮지 말아야..도쿄 올림픽서 금메달 못 따 울어도 되지만, 메달 받자마자 벗지는 말라\n",
      "                                    \n",
      "https://v.daum.net/v/20210713132823219 : 중앙여고, 아무도 가지 못한 대회 12연패\n",
      "                                    \n",
      "https://v.daum.net/v/20210713145351558 : 샌드박스는 왜 부산으로 향하나\n",
      "                                    \n",
      "https://v.daum.net/v/20210713112036842 : 점심 먹던 2군 포수까지 불렀는데..'리그 중단'에 빛바랜 KIA 모범 답안 \n",
      "                                    \n",
      "https://v.daum.net/v/20210713123653039 : '실축' 래시포드 \"전 23세고, 맨체스터 남부 출신의 흑인입니다\" \n",
      "                                    \n",
      "https://v.daum.net/v/20210713150034872 : 박찬호, 또 프로대회에 도전한다..초청선수로 프로골프 코리안투어 네 번째 도전\n",
      "                                    \n",
      "https://v.daum.net/v/20210713110019690 : 사카 실축하자 곧바로 뛰어온 '리즈 MF', 품에 꼭 안았다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713140002293 : '홈런 기계' 알론소, 홈런더비 우승 상금이 3년 연봉보다 많다\n",
      "                                    \n",
      "https://v.daum.net/v/20210713104446895 : '괴물' 오타니, 홈런 더비 1R 탈락..'35홈런 폭발' 알론소 2R 진출\n",
      "                                    \n",
      "https://v.daum.net/v/20210713102136943 : 오타니, 영어 못하는 게 문제? ESPN 진행자 사과 \"무감각했다\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713120023976 : 프로야구, 판이 바뀌었다..삼성‧SSG 약진-NC‧두산 부진\n",
      "                                    \n",
      "https://v.daum.net/v/20210713142436296 : '호펜하임행 유력' 이재성, 마인츠로 급선회한 이유는?\n",
      "                                    \n",
      "https://v.daum.net/v/20210713120715329 : 알 가라파, 구자철과 작별..\"수고에 감사, 행운을 빈다\"\n",
      "                                    \n",
      "https://v.daum.net/v/20210713125022341 : 'Sho-time!' 오타니, 1R 탈락에도 열광..152m 특대탄 역대 최다\n",
      "                                    \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lstrip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-49eec3693f55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#print(c_list[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lstrip'"
     ]
    }
   ],
   "source": [
    "##mAside > div.aside_g.aside_ranking > ul > li:nth-child(1) > a\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "\n",
    "# HTML\n",
    "url = \"https://news.daum.net/digital#1\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "c_list = soup.select('div.cont_aside li a')\n",
    "#print(c_list[0])\n",
    "for c in c_list:\n",
    "    print(c['href'], \":\" , c.string.lstrip())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_list:\n",
    "    print(c.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356acdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a47525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ad38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24a85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae954270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d265b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75829274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b91be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f227f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
